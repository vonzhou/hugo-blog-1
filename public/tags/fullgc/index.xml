<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FullGC on 编程之路</title>
    <link>http://vonzhou.com/tags/fullgc/</link>
    <description>Recent content in FullGC on 编程之路</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://vonzhou.com/tags/fullgc/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>记一次使用KafkaProducer引发的Full GC问题</title>
      <link>http://vonzhou.com/2019/kafka-producer-fullgc-story/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://vonzhou.com/2019/kafka-producer-fullgc-story/</guid>
      <description> 场景 一个模块接收数据，然后投到Kafka中，实现削峰填谷。突然有一天频繁出现Full GC问题。
初步尝试 查看JVM的配置，发现最大堆配置的太小，推测：堆内存不足，导致频繁gc，内存不足，导致往kafka发送消息的时候阻塞，所以线程都会卡住。
15302 com.xxxx.AppRunner -Dlog.dir=/path/to/logs -Xms1024m -Xmx1024m -XX:MaxPermSize=256m -verbose:gc -XX:+PrintGCDetails  调整堆大小配置后，Full GC 问题并没有得到缓解。
MAT分析 heap dump出现使用MAT分析。
这里的大对象都是我们发送的批量消息对象，推测：是不是batch.size设置的过大？（设置的是40MB）
解决方法 调小batch.size，设置为20MB：
props.put(&amp;quot;buffer.memory&amp;quot;, 100 * 1024 * 1024); // 批量发送的字节大小， 20MB props.put(&amp;quot;batch.size&amp;quot;, 2 * 10 * 1024 * 1024);  最终问题得以解决，连Minor GC也很少了：
KafkaProducer消息发送过程 KafkaProducer发送消息的过程是：消息追加到一个内部的队列中，有一个异步线程负责从中取出，将消息发送给Broker。
在了解kafka消息发送过程的基础上，通过MAT大对象图还可以看到：
 buffer.memory配置的是客户端发送消息时BufferPool的内存大小，至少要比batch.size大，否则连一个RecordBatch也放不进去。 实际占用的内存可能是buffer.memory的好几倍（4~5倍？），流转多个环节，底层存储都是ByteBuffer  </description>
    </item>
    
  </channel>
</rss>